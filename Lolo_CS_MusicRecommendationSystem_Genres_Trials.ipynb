{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoderSchool Final Project Genres\n",
    "## Music Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we will work with the MasterSongList data. Let's see later on if we can use a more detailed dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the genre analysis, since there are 29 genres after cleaning the data, this will be a multi class problem. Here are the classifiers that we will use, all of them are compatible with multiclass:\n",
    "- kNN\n",
    "- Logistic Regression OVR\n",
    "- or Logistic Regression OVO\n",
    "- SVC OVR (default)\n",
    "- or SVC OVO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to try both OVO and OVR for LogReg and SVC but will only keep one of the 2.\n",
    "For all of these models we will use a Pipeline to combine the classifier with GridSearchCV (optimize parameters) and SelectKBest (optimize features)\n",
    "The results will be compared using VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_json('MasterSongList.json')\n",
    "full_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove the list format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df2 = full_df.copy()\n",
    "full_df2['genres'] = full_df2['genres'].apply(''.join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And only want to keep the first genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_first_genre(genre):\n",
    "    if len(genre) > 0:\n",
    "        return genre.split(':')[0]\n",
    "    else:\n",
    "        return genre\n",
    "\n",
    "full_df2['genres'] = full_df2['genres'].apply(split_first_genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what genres are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genres = full_df2['genres'].unique()\n",
    "unique_genres.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genres.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now only want to keep the audio features and the genre, let's create a new dataframe: df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_headers = ['key', 'energy', 'liveliness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'duration', 'loudness', 'valence', 'danceability', 'mode', 'time_signature_confidence', 'tempo_confidence', 'key_confidence', 'mode_confidence']\n",
    "features_list = full_df2['audio_features'].tolist()\n",
    "df = pd.DataFrame(features_list, columns=features_headers)\n",
    "df['genres'] = full_df2['genres']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the songs with no genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['genres'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the NaN rows and their distribution among the genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checknan(x):\n",
    "    return np.isnan(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_df = ['bluegrass', 'blues & blues rock', \"children's\", 'christian', 'classical', 'country', 'dance', \"dubstep & drum 'n' bass\", 'easy listening', 'electronica', 'film scores', 'folk', 'funk', 'hawaiian ', 'indie', \"int'l\", 'international/world', 'jazz', 'latin', 'nature sounds', 'oldies', 'pop', 'r&b', 'rap', 'reggae & ska', 'reggaeton', 'rock', 'showtunes', 'singer-songwriter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in genres_df:\n",
    "    songs = df[df['genres'] == i]\n",
    "    genres_nan = songs['speechiness'].apply(checknan)\n",
    "    print(i)\n",
    "    print(genres_nan.value_counts())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is quite disbalanced. First, let's:\n",
    "- drop the NaN rows when count is above 1000\n",
    "- replace the NaN rows values by the median of the others when under 1000\n",
    "- combine some of the similar genres with low number of rows: international & hawai, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let'd group all the international songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal.loc[(df_bal['genres'].str.contains(\"hawa\")), 'genres'] = 'international/world'\n",
    "df_bal.loc[(df_bal['genres'] == \"int'l\"), 'genres'] = 'international/world'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I am not too sure what 'showtunes' is, let's look at a few samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df2[full_df2['genres'] == 'showtunes'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be grouped with 'film_scores' as 'film/show'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal.loc[(df_bal['genres'] == 'showtunes'), 'genres'] = 'film/show'\n",
    "df_bal.loc[(df_bal['genres'] == 'film scores'), 'genres'] = 'film/show'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal['genres'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's differentiate genres that have more/less than 1000 non-NaN rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_genres_df = ['bluegrass', 'blues & blues rock', \"children's\", 'christian', 'classical', 'country', 'dance', \"dubstep & drum 'n' bass\", 'easy listening', 'electronica', 'film/show', 'folk', 'funk', 'indie', 'international/world', 'jazz', 'latin', 'nature sounds', 'oldies', 'pop', 'r&b', 'rap', 'reggae & ska', 'reggaeton', 'rock', 'singer-songwriter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_genres = []\n",
    "small_genres = []\n",
    "\n",
    "for i in new_genres_df:\n",
    "    songs_genre = df_bal[df_bal['genres'] == i]\n",
    "    songs_genre_nan = songs_genre['speechiness'].apply(checknan)\n",
    "    if len(songs_genre_nan[songs_genre_nan == False]) >= 1000:\n",
    "        large_genres.append(i)\n",
    "    else:\n",
    "        small_genres.append(i)\n",
    "\n",
    "print(large_genres)\n",
    "print(small_genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop NaN on large genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "\n",
    "for i in large_genres:\n",
    "    songs = df_bal[df_bal['genres'] == i]\n",
    "    new_songs = songs.dropna(axis=0, how='any')\n",
    "    new_df = pd.concat([new_df, new_songs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's replace NaN by median on small genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in small_genres:\n",
    "    songs = df_bal[df_bal['genres'] == i]\n",
    "    new_songs = songs.fillna(songs.median())\n",
    "    new_df = pd.concat([new_df, new_songs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we don't have any NaN value left. However we can see below that the dataframe is not well balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['genres'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Select data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's randomize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.sample(frac=1, random_state=101).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.drop('genres', axis=1)\n",
    "y = new_df['genres']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scale = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over and undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid imbalanced data, we will also try to use a combination of over and under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "sorted(Counter(y).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_resampled, y_resampled = smote_enn.fit_sample(X_scale, y)\n",
    "sorted(Counter(y_resampled).items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now also have 2 new data sources: X_resampled and y_resampled on which we could test our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Try classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all our classifiers we will use a pipeline (classifier + SelectKBest) as we as GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the classifiers we are going to try:\n",
    "- kNN on X_scale and y\n",
    "- kNN on X_resampled and y_resampled\n",
    "- LogReg on X_scale and y\n",
    "- LogReg on X_resampled and y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN1 on X_scale and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.1, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn1 = KNeighborsClassifier()\n",
    "selector1 = SelectKBest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_knn1 = [('feature_selection', selector1), ('kneighbors', knn1)]\n",
    "parameters_knn1 = dict(feature_selection__k=[5,7,10,12], kneighbors__n_neighbors=[3,5,7,10])\n",
    "pipeline_knn1 = Pipeline(steps_knn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_knn1 = GridSearchCV(pipeline_knn1, param_grid=parameters_knn1, verbose=3)\n",
    "grid_knn1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_knn1.best_estimator_)\n",
    "predictions_knn1 = grid_knn1.predict(X_test)\n",
    "print(classification_report(y_test, predictions_knn1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that nature sounds has a result of 1 because there was probably no data in the test sample. Let's try this classifier again with the resampled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN on X_resampled and y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.1, random_state=101)\n",
    "knn2 = KNeighborsClassifier()\n",
    "selector2 = SelectKBest()\n",
    "steps_knn2 = [('feature_selection', selector2), ('kneighbors', knn2)]\n",
    "parameters_knn2 = dict(feature_selection__k=[5,7,10,12], kneighbors__n_neighbors=[3,5,7,10])\n",
    "pipeline_knn2 = Pipeline(steps_knn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_knn2 = GridSearchCV(pipeline_knn2, param_grid=parameters_knn2, verbose=3)\n",
    "grid_knn2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_knn2.best_estimator_)\n",
    "predictions_knn2 = grid_knn2.predict(X_test)\n",
    "print(classification_report(y_test, predictions_knn2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that the resampled data gives way better results. We will keep only this kNN classifier as the first result is too low. However we can note the computation time increased significantly: so we will reduce some of the parameters later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: we should be careful about overfitting with this specific model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also use GridSearchCV for LogReg but we will include more parameters as several things might be interesting: class_weight (to balance automatically the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.1, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = LogisticRegression(max_iter=5000, class_weight='balanced')\n",
    "selector_lr1 = SelectKBest()\n",
    "steps_lr1 = [('feature_selection', selector_lr1), ('LogReg', lr1)]\n",
    "parameters_lr1 = dict(feature_selection__k=[5,8,12], \n",
    "                      LogReg__solver=['newton-cg', 'sag', 'saga', 'lbfgs'],\n",
    "                      LogReg__multi_class=['ovr', 'multinomial'])\n",
    "\n",
    "pipeline_lr1 = Pipeline(steps_lr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lr1 = GridSearchCV(pipeline_lr1, param_grid=parameters_lr1, verbose=3)\n",
    "grid_lr1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_lr1.best_estimator_)\n",
    "predictions_lr1 = grid_lr1.predict(X_test)\n",
    "print(classification_report(y_test, predictions_lr1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the same thing ut without the balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression(max_iter=5000)\n",
    "selector_lr2 = SelectKBest()\n",
    "steps_lr2 = [('feature_selection', selector_lr2), ('LogReg', lr2)]\n",
    "parameters_lr2 = dict(feature_selection__k=[5,8,12], \n",
    "                      LogReg__solver=['newton-cg', 'sag', 'saga', 'lbfgs'],\n",
    "                      LogReg__multi_class=['ovr', 'multinomial'])\n",
    "\n",
    "pipeline_lr2 = Pipeline(steps_lr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lr2 = GridSearchCV(pipeline_lr2, param_grid=parameters_lr2, verbose=3)\n",
    "grid_lr2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_lr2.best_estimator_)\n",
    "predictions_lr2 = grid_lr2.predict(X_test)\n",
    "print(classification_report(y_test, predictions_lr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=‘orange’> Also look at resampled data </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC on X_scaled and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.1, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc1 = SVC()\n",
    "selector_svc1 = SelectKBest()\n",
    "steps_svc1 = [('feature_selection', selector_svc1), ('SVC', svc1)]\n",
    "parameters_svc1 = dict(feature_selection__k=[5,8,12], \n",
    "                      SVC__C=[0.1,1, 10],\n",
    "                      SVC__gamma=[1,0.1,0.01,0.001],\n",
    "                      SVC__decision_function_shape :[‘ovo’, ‘ovr’,])\n",
    "\n",
    "pipeline_svc1 = Pipeline(steps_svc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svc1 = GridSearchCV(pipeline_svc1, param_grid=parameters_svc1, verbose=3)\n",
    "grid_svc1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_svc1.best_estimator_)\n",
    "predictions_svc1 = grid_svc1.predict(X_test)\n",
    "print(classification_report(y_test, predictions_svc1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=‘orange’> Comments</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=‘orange’> Later: voting classifier </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
